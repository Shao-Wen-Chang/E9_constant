{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 902,
   "id": "f78c3858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import util_match\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "id": "5727b7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_plot = False   # set to false if gathering matching data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795ec37b",
   "metadata": {},
   "source": [
    "# Reading data\n",
    "In case that we get different EoS using the same folder parameters in the future, I'll also keep track of the EoS file. For this I think the file modification time is sufficient.\n",
    "\n",
    "Unfinished runs are detected by mismatches in the length of beta.\n",
    "\n",
    "How I treat folder parameters:\n",
    "* $\\mu$, $V$, $t_p$ and $shift$ are things we expect to be different in a folder. All the other parameters should be the same; I include them in `folder_params_shared` and check for every folder.\n",
    "    * Among them, $\\mu$ is additionally saved in `data_in_measurements[\"mu\"]`. I check that this indeed matches the one specified in the folder name.\n",
    "    * For $V$, $t_p$ and $shift$, I don't do the filtering until all the data are loaded.\n",
    "* I assume $t = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "id": "6bb32303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I had to keep the data files in the download folder, otherwise the folder names are too long\n",
    "data_folder = Path(r\"C:\\Users\\ken92\\Downloads\\Shao-Wen Data\")\n",
    "# Interacting\n",
    "tnpspc = {  # tenpy specs used to generate folder names\n",
    "    \"geometry\": \"sawtooth\",\n",
    "    \"spin\": \"spinless\",      # \"spinful\", \"spinless\"\n",
    "    \"interacting\": \"I\",             # \"I\", \"NI\"\n",
    "    \"L\": 25,\n",
    "    \"chi\": 64,\n",
    "}\n",
    "V_model = -0.1\n",
    "shift_model = -2\n",
    "tp_model = 1.41421356237\n",
    "# scan_name = f\"{tnpspc['geometry']}_{tnpspc['spin']}_I_L{tnpspc['L']}_chi{tnpspc['chi']}.tar\"\n",
    "scan_name = f\"ST_SL_I_L25_t1_tpsqrt2_shf{shift_model}_V{V_model}_chi64\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3275adde",
   "metadata": {},
   "source": [
    "Interacting and non-interacting data is stored differently and require different unpacking methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "id": "cbc7f4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 49 folders\n"
     ]
    }
   ],
   "source": [
    "folder_params_shared = None\n",
    "records_EoS = []\n",
    "scan_folder = Path(data_folder, scan_name)\n",
    "assert scan_folder.exists()\n",
    "\n",
    "subfolder_list = [f for f in scan_folder.iterdir() if f.is_dir()]\n",
    "print(f\"found {len(subfolder_list)} folders\")\n",
    "\n",
    "first_betas = None\n",
    "for i_f, sf_path in enumerate(subfolder_list):\n",
    "    # Load data and store them as panda data rows\n",
    "    filepath = Path(sf_path, \"measurements.pkl\")\n",
    "    assert filepath.is_file()\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        file_content = pickle.load(f)\n",
    "\n",
    "    try:\n",
    "        folder_params = util_match.parse_folder_name(sf_path)\n",
    "        \n",
    "        # Check mu consistency between folder name and file\n",
    "        mu = file_content['mu']\n",
    "        if not np.isclose(mu, folder_params['mu']):\n",
    "            raise(ValueError(f\"mu_folder = {folder_params['mu']} doesn't agree with mu_file = {mu}\"))\n",
    "        else:\n",
    "            folder_params.pop(\"mu\")\n",
    "        \n",
    "        # Check shared folder parameters\n",
    "        V = folder_params.pop(\"V\")\n",
    "        shift = folder_params.pop(\"shift\")\n",
    "        tp = folder_params.pop(\"tp\")\n",
    "        if folder_params_shared is None:\n",
    "            folder_params_shared = folder_params.copy()\n",
    "            for k, v in tnpspc.items():\n",
    "                if folder_params_shared[k] != v:\n",
    "                    raise(ValueError(\"mismatch in tenpy parameters\"))\n",
    "        else:\n",
    "            if folder_params != folder_params_shared:\n",
    "                print(folder_params)\n",
    "                print(folder_params_shared)\n",
    "                raise(ValueError(\"mismatch in folder parameters\"))\n",
    "\n",
    "        # Save data\n",
    "        for i_b, beta in enumerate(file_content['betas']):\n",
    "            S2, n_avg, energy, eps, ov, max_chi, trace, runtime = file_content['data'][i_b, :]\n",
    "            records_EoS.append({\n",
    "                \"mu\": file_content['mu'],\n",
    "                \"beta\": beta,\n",
    "                \"S2\": S2,\n",
    "                \"n_avg\": n_avg,\n",
    "                \"energy\": energy,\n",
    "                \"eps\": eps,\n",
    "                \"ov\": ov,\n",
    "                \"max_chi\": max_chi,\n",
    "                \"trace\": trace,\n",
    "                \"runtime\": runtime,\n",
    "                \"file_mtime\": os.path.getmtime(filepath),\n",
    "                \"V\": V,\n",
    "                \"shift\": shift,\n",
    "                \"tp\": tp\n",
    "            })\n",
    "    except ValueError as e:\n",
    "        print(filepath)\n",
    "        raise(e)\n",
    "\n",
    "    # Check beta length and print warnings if they don't look right\n",
    "    if first_betas is None:   # assuming that the first subfolder has the right length of data\n",
    "        first_betas = file_content['betas']\n",
    "        continue\n",
    "    else:\n",
    "        len_good = (len(file_content['betas']) == len(first_betas))      # length is good\n",
    "        if len_good: # content is also good\n",
    "            if np.allclose(file_content['betas'], first_betas):\n",
    "                continue\n",
    "    print(f\"beta doesn't agree for {filepath}\")\n",
    "    print(f\"getting {file_content['betas']}\")\n",
    "\n",
    "df_all_data = pd.DataFrame.from_records(records_EoS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a81a46",
   "metadata": {},
   "source": [
    "## Filter parameters using Dataframe\n",
    "Currently I only consider joined systems with the same interaction strength everywhere.\n",
    "\n",
    "### Specify filter parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "id": "7bd980ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_params = {\"V\": V_model, \"shift\": shift_model, \"tp\": tp_model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "id": "6c64f5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each subregion contains 25 unit cells\n"
     ]
    }
   ],
   "source": [
    "L_subregion = tnpspc[\"L\"]    # We checked consistency for this one\n",
    "print(f\"Each subregion contains {L_subregion} unit cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "id": "0695886b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_all_data.query(f\"(V == {V_model}) & (shift == {shift_model})\")\n",
    "idx_list = [\"mu\", \"beta\"]\n",
    "df_filtered = df_filtered.set_index(idx_list).sort_index()\n",
    "\n",
    "# df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a656ee",
   "metadata": {},
   "source": [
    "## Plots\n",
    "Even for finite interaction strengths, we still see a trace of the flat band in the $S_{2, avg}$ plot. For example, for the $V = 1$, shift $= 2$ single layer sawtooth, we see an enhancement in entropy around $\\mu = 0.5$. I would have naively guessed that this should happen at $\\mu = 0.25$ instead by looking at the completely localized states (CLS):\n",
    "* The wave function of CLS lives on two neighboring teeth, and has values of $1 / \\sqrt(2)$ on the shared A site, and $1 / 2$ on the two B sites.\n",
    "    * i.e. there's half a particle on the A site and a quarter of a particle each on the B sites\n",
    "* Each of the link then gets an energy of $1/2 \\cdot 1/4 \\cdot V = 1/8$.\n",
    "* There are two links, so the shift in energy for each CLS is $1/8 \\cdot 2 = 1/4$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "id": "3c15436a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_vals  = df_filtered.index.get_level_values(\"mu\").unique().to_numpy()\n",
    "beta_vals = df_filtered.index.get_level_values(\"beta\").unique().to_numpy()\n",
    "n_grid = df_filtered[\"n_avg\"].unstack(\"beta\").loc[mu_vals, beta_vals].to_numpy()    # particle per site\n",
    "s2_grid = df_filtered[\"S2\"].unstack(\"beta\").loc[mu_vals, beta_vals].to_numpy()       # Renyi 2-entropy per particle\n",
    "e_grid = df_filtered[\"energy\"].unstack(\"beta\").loc[mu_vals, beta_vals].to_numpy()   # energy per particle\n",
    "eps_grid = df_filtered[\"eps\"].unstack(\"beta\").loc[mu_vals, beta_vals].to_numpy()    # sum of all discarded Schmidt values squared\n",
    "ov_grid = df_filtered[\"ov\"].unstack(\"beta\").loc[mu_vals, beta_vals].to_numpy()      # lower bound for the overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "id": "89ab2e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if bool_plot:\n",
    "    fig_ns, axes_ns = plt.subplots(2, 2, figsize = (8, 7))\n",
    "    for ax, vals, str_label, clim in zip(axes_ns.flatten(),\n",
    "                        [n_grid, s2_grid, e_grid, 1 - ov_grid],\n",
    "                        [\"n_avg\", \"S2_avg\", \"E\", \"max infidelity\"],\n",
    "                        [None, (0., 0.4), None, (0, 0.005)],):\n",
    "        img = ax.pcolormesh(beta_vals, mu_vals, vals, clim = clim)\n",
    "        ax.set_box_aspect(1)\n",
    "        ax.set_title(str_label)\n",
    "        ax.set_xlabel(r\"$\\beta$\")\n",
    "        ax.set_ylabel(r\"$\\mu$\")\n",
    "        cntr = ax.contour(beta_vals, mu_vals, vals, colors = \"white\", linestyles = \"solid\", levels = 8)\n",
    "        ax.clabel(cntr, inline = True)\n",
    "        fig_ns.colorbar(img, ax = ax)\n",
    "    fig_ns.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd384813",
   "metadata": {},
   "source": [
    "# Actual calculations\n",
    "Goal: given our equations of state $n(\\mu, \\beta)$ and $s_2(\\mu, \\beta)$, achieve some filling factor $n_s$ in the system for different $(N_{tot}, S_{tot})$\n",
    "(This also fixes $N_r = N_{tot} - 2 n_s L$, or equivalently $n_r = 2n - n_s$)\n",
    "1. Find $\\mu_{s, r} = \\mu(\\beta) |_{n(\\mu, \\beta) = n_{s, r}}$ by inverting $n(\\mu, \\beta)$. I can do this for all $\\beta$.\n",
    "2. Find $s_2(\\mu_{s, r}, \\beta)$. As I vary $\\beta$ I should get a smooth change in $S_2 = 2 L (s_2(\\mu_s) + s_2(\\mu_r))$, so the scan in $S_{tot}$ comes for free.\n",
    "3. Do this for different $N_{tot}$. Now I've in principle done a scan in the $(N, S)$ space.\n",
    "\n",
    "(Take $L_s = L_r = L$ for now, where $L$ is the number of unit cells, so there are $2L$ sites in each subregion)\n",
    "\n",
    "Here we get $(n_s; N_{tot}, \\beta) \\rightarrow (\\mu_s, \\mu_r, S_{tot})$, where I additionally define\n",
    "* $V_{offset} = \\mu_r - \\mu_s$ is the offset potential required to achieve $n_s$.\n",
    "* $\\mu \\equiv \\mu_r$ --- this one is somewhat arbitrary. Effectively, I'm assuming that $V_{offset}$ is a potential that only increases the potential energy in the system region, while leaving the reservoir region intact. This is the case for our experimental setup, since our DMD light is blue-detuned.\n",
    "* $n = N_{tot} / 4L$\n",
    "\n",
    "I write a semicolon for $n_s$ because it is not really a thermodynamic variable in the usual sense, but not including that gives one the wrong impression that the relation is underdetermined. (i.e. I want to have the same number of values on both side)\n",
    "\n",
    "## $N_{tot}$ and $S_{tot}$ matching\n",
    "We'll see how well ChatGPT implement this algorithm in 48 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7c8b65",
   "metadata": {},
   "source": [
    "### Scan $N_{tot}$ (jump here to change $n_s$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1055,
   "id": "2119390d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx_beta_scan = (beta_vals >= 2.)       # Otherwise the contours will be concentrated at small beta where things are boring\n",
    "idx_beta_scan = (beta_vals >= -1.)      # All beta, use this for the .csv file\n",
    "beta_scan = beta_vals[idx_beta_scan]\n",
    "n_s_tar = 0.68   # target filling in the system\n",
    "\n",
    "N_tot_arr = np.arange((n_s_tar + 0.) * 2 * L_subregion, (n_s_tar + 1) * 2 * L_subregion + 1, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1056,
   "id": "1286876a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_s_tar = n_s_tar * L_subregion * 2\n",
    "assert N_s_tar <= N_tot_arr[-1], f\"there must be at least {N_s_tar} particles\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1057,
   "id": "6bc56b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_beta = beta_scan.size\n",
    "N_Ntot = N_tot_arr.size\n",
    "\n",
    "mu_s_all  = np.full((N_Ntot, N_beta), np.nan)\n",
    "mu_r_all  = np.full((N_Ntot, N_beta), np.nan)\n",
    "s2_s_all  = np.full((N_Ntot, N_beta), np.nan)\n",
    "s2_r_all  = np.full((N_Ntot, N_beta), np.nan)\n",
    "S2_tot_all = np.full((N_Ntot, N_beta), np.nan)\n",
    "n_r_arr   = np.full(N_Ntot, np.nan)\n",
    "\n",
    "for k, N_tot in enumerate(N_tot_arr):\n",
    "    # global filling n and reservoir filling n_r\n",
    "    n_global = N_tot / (4.0 * L_subregion)\n",
    "    n_r = 2.0 * n_global - n_s_tar   # equivalently: N_tot/2L - n_s\n",
    "    n_r_arr[k] = n_r\n",
    "\n",
    "    # 1) invert n(mu, beta) to get mu_s(beta) and mu_r(beta)\n",
    "    mu_s = util_match.invert_n_to_mu(mu_vals, beta_scan, n_grid[:, idx_beta_scan], n_s_tar)\n",
    "    mu_r = util_match.invert_n_to_mu(mu_vals, beta_scan, n_grid[:, idx_beta_scan], n_r)\n",
    "\n",
    "    mu_s_all[k, :] = mu_s\n",
    "    mu_r_all[k, :] = mu_r\n",
    "\n",
    "    # 2) evaluate s2 at those mus\n",
    "    s2_s = util_match.s2_at_mu(mu_vals, beta_scan, s2_grid[:, idx_beta_scan], mu_s)\n",
    "    s2_r = util_match.s2_at_mu(mu_vals, beta_scan, s2_grid[:, idx_beta_scan], mu_r)\n",
    "\n",
    "    s2_s_all[k, :] = s2_s\n",
    "    s2_r_all[k, :] = s2_r\n",
    "\n",
    "    # 3) total S2\n",
    "    S2_tot_all[k, :] = L_subregion * (s2_s + s2_r)\n",
    "\n",
    "dmu_all = mu_r_all - mu_s_all\n",
    "mu_glob_all = mu_r_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1058,
   "id": "a8d65db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, data in [(\"mu_s\", mu_s_all), (\"mu_r\", mu_r_all), (\"s2_s\", s2_s_all), (\"s2_r\", s2_r_all)]:\n",
    "    if np.all(np.isnan(data)):\n",
    "        raise(ValueError(f\"No legal values for {label} within the range of input\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cda7250",
   "metadata": {},
   "source": [
    "We are interested in knowing when we can realize $s_r > s_s$. I'll define a dimensionless figure of merit\n",
    "\n",
    "$\\varsigma \\equiv s_s / s - 1 = (s_s - s_r) / (s_s + s_r)$ (assume $L_r = L_s$)\n",
    "\n",
    "that measures the decrease in entropy, measured in entropy per particle if there were no offset. $\\varsigma < 0$ indicates cooling effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1059,
   "id": "d24292fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "varsigma_all = (s2_s_all - s2_r_all) / (s2_s_all + s2_r_all)\n",
    "min_varsigma = np.nanmin(varsigma_all.flatten())    # best cooling obtained\n",
    "\n",
    "# masking arrays derived from varsigma\n",
    "varsigma_all_nonan = np.nan_to_num(varsigma_all)\n",
    "mask_alpha_cooling = np.minimum(varsigma_all_nonan, 0.) / min_varsigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1060,
   "id": "0bd39b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-0.09130972651007722)"
      ]
     },
     "execution_count": 1060,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_varsigma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0715b973",
   "metadata": {},
   "source": [
    "### Plots\n",
    "The amount of cooling is, of course, shaded in red, in each axes. The last axes is a standalone visualization for it that has a fixed color range.\n",
    "* $s_s$ plot is by definition boring, since $N_{tot}$ doesn't change $n_s$.\n",
    "* $s_r$ plot has more feature because $n_r$ depends on $N_{tot}$.\n",
    "* $S_{tot}$\n",
    "* $\\mu$\n",
    "* $V_{offset}$ tells us the required offset we need to achieve $n_s$ in the system.\n",
    "* $\\varsigma$: the red grids in other axeses are scaled to the maximum amount of cooling. This one always use the same scale for comparison between different input parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1061,
   "id": "fc8e78a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if bool_plot:\n",
    "    fig_eos, axes_eos_all = plt.subplots(2, 3 * 2, figsize = (13, 7), gridspec_kw = {\"width_ratios\": [15, 1] * 3})\n",
    "    axes_eos = axes_eos_all[:, ::2]\n",
    "    axes_eos_cb = axes_eos_all[:,1::2]\n",
    "    alpha_cooling_max = 0.3\n",
    "    for ax, ax_cb, vals, cmap, str_label, clim in zip(axes_eos.flatten(), axes_eos_cb.flatten(),\n",
    "                        [s2_s_all, s2_r_all, S2_tot_all, mu_glob_all, dmu_all, varsigma_all],\n",
    "                        [\"viridis\", \"viridis\", \"viridis\", \"viridis\", \"viridis\", \"coolwarm\"],\n",
    "                        [r\"$s_s$\", r\"$s_r$\", r\"$S_{tot}$\", r\"$\\mu$\", r\"$V_{offset}$\", r\"$\\varsigma$\"],\n",
    "                        [None, None, None, None, None, (-1, 1)]):\n",
    "        img = ax.pcolormesh(beta_scan, N_tot_arr, vals, clim = clim, cmap = cmap)\n",
    "        ax.set_box_aspect(1)\n",
    "        ax.set_title(str_label)\n",
    "        ax.set_xlabel(r\"$\\beta$\")\n",
    "        ax.set_ylabel(r\"$N_{tot}$\")\n",
    "        ryax = ax.secondary_yaxis('right', functions = (lambda x: (x - N_s_tar) / (2 * L_subregion), lambda x: x * 2 * L_subregion + N_s_tar))\n",
    "        ryax.set_ylabel(r\"$n_r$\")\n",
    "        cntr = ax.contour(beta_scan, N_tot_arr, vals, colors = \"white\", linestyles = \"solid\", levels = 10)\n",
    "        ax.clabel(cntr, inline = True)\n",
    "        fig_eos.colorbar(img, cax = ax_cb, fraction = 0.5, location = 'right')\n",
    "        # ax_cb.imshow(np.arange(16).reshape(4,4))\n",
    "        if str_label != r\"$\\varsigma$\":\n",
    "            ax.pcolormesh(beta_scan, N_tot_arr, np.ones_like(vals), clim = (0, 1), color = \"red\",# lw = 0.,\n",
    "                        alpha = mask_alpha_cooling * alpha_cooling_max)\n",
    "    fig_eos.suptitle(rf\"results from EoS matching - $n_s =${n_s_tar} ($N_s =${N_s_tar})\")\n",
    "    fig_eos.tight_layout(w_pad = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c8f910",
   "metadata": {},
   "source": [
    "Now, we scanned $\\beta$ because it is easier to do, but we will be more interested in scanning total entropy. This is done in `matching_result_inverter.ipynb`.\n",
    "\n",
    "### Building the matching results Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1062,
   "id": "f31e2d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "records_matching = []\n",
    "for i_beta, beta in enumerate(beta_scan):\n",
    "    for i_Ntot, Ntot in enumerate(N_tot_arr):\n",
    "        records_matching.append({\n",
    "            \"beta\": beta,\n",
    "            \"Ntot\": Ntot,\n",
    "            \"n_s\": n_s_tar,\n",
    "            \"n_r\": n_r_arr[i_Ntot],\n",
    "            \"mu_s\": mu_s_all[i_Ntot, i_beta],\n",
    "            \"mu_r\": mu_r_all[i_Ntot, i_beta],\n",
    "            \"V_offset\": dmu_all[i_Ntot, i_beta],\n",
    "            \"mu_glob\": mu_glob_all[i_Ntot, i_beta],\n",
    "            \"s2_s\": s2_s_all[i_Ntot, i_beta],\n",
    "            \"s2_r\": s2_r_all[i_Ntot, i_beta],\n",
    "            \"S2_tot\": S2_tot_all[i_Ntot, i_beta],\n",
    "            \"varsigma\": varsigma_all[i_Ntot, i_beta],\n",
    "            \"file_mtime\": os.path.getmtime(filepath)\n",
    "        } | filter_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1063,
   "id": "0fecbbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matching_rslt = pd.DataFrame.from_records(records_matching)\n",
    "# df_matching_rslt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb4dcfa",
   "metadata": {},
   "source": [
    "### Save to .csv\n",
    "I'll treat the following as input parameters:\n",
    "* All the original folder parameters except for $\\mu$.\n",
    "* $\\beta$, $N_{tot}$, $n_s$\n",
    "* EoS file modification time\n",
    "\n",
    "A new row of data is added for each input parameters. If an entry with the same input parameters already exists in `csv_path`, we compare if the obtained results agree with the existing ones. If not, we print a warning but leaves the original result unchanged and move on.\n",
    "\n",
    "Saving everything to a single .csv makes the comparison very slow (several minutes), so I make a new .csv for each $V$, $t_p$, $shift$, and $n_s$. For parameters in the name of .csv, the parameter comparison is done when looking for an existing `csv_path`.\n",
    "\n",
    "If all the input parameters are the same except for the file modification time, the original entry is replaced if `bool_overwrite_older_mtime = True`, or a new row is added if it is `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1064,
   "id": "14070051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise(Exception(\"Imma stop here\"))  # comment this out to actually save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1065,
   "id": "17a45de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_param_cols = [k for k in filter_params.keys()] + [\n",
    "    \"beta\",\n",
    "    \"Ntot\",\n",
    "    \"n_s\",\n",
    "    \"file_mtime\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac24049",
   "metadata": {},
   "source": [
    "Check the number of rows existed in .csv if this is something I've run before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1066,
   "id": "1a67bd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_results_folder = Path(r\"C:\\Users\\ken92\\Documents\\Studies\\E5\\simulation\\E9_simulations\\projects\\flat_band_cooling\\tenpy_results\\matching_results\",\n",
    "                               scan_name.removesuffix(\".tar\"))\n",
    "matching_results_folder.mkdir(exist_ok = True)\n",
    "csv_name = f\"V{filter_params['V']}_tp{filter_params['tp']}_shift{filter_params['shift']}_ns{n_s_tar}.csv\"\n",
    "csv_path = Path(matching_results_folder, csv_name)\n",
    "\n",
    "df_matching_rslt.to_csv(csv_path, index = False)\n",
    "# util_match.update_eos_csv(\n",
    "#     df_new = df_matching_rslt,\n",
    "#     csv_path = csv_path,\n",
    "#     param_cols = input_param_cols,\n",
    "#     bool_overwrite_conflict = True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5e57a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
